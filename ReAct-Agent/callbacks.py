# This is for callback handlers
from typing import Dict, Any, List, Optional
from uuid import UUID

from langchain_core.callbacks import BaseCallbackHandler
from langchain_core.outputs import LLMResult


class AgentCallbackHandler(BaseCallbackHandler):
    def on_llm_start(
            self,
            serialized: Dict[str, Any],
            prompts: List[str],
            *,
            run_id: UUID,
            parent_run_id: Optional[UUID] = None,
            tags: Optional[List[str]] = None,
            metadata: Optional[Dict[str, Any]] = None,
            **kwargs: Any,
    ) -> Any:
        """Run when LLM starts running."""
        print("--------------------------------------------")
        print("Prompts received by LLM on starting stage ----> ")
        print(x for x in prompts)
        print("--------------------------------------------")
        print("\n")

    def on_llm_end(
            self,
            response: LLMResult,
            *,
            run_id: UUID,
            parent_run_id: Optional[UUID] = None,
            **kwargs: Any,
    ) -> Any:
        """Run when LLM ends running."""
        print("--------------------------------------------")
        print("Response Generated by the LLM on ending ----> ")
        print(f"{response.generations[0][0].text}")
        print("--------------------------------------------")
        print("\n")
